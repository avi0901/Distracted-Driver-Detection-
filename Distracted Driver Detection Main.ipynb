{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T06:42:57.835239Z",
     "iopub.status.busy": "2022-02-23T06:42:57.834852Z",
     "iopub.status.idle": "2022-02-23T06:43:03.235466Z",
     "shell.execute_reply": "2022-02-23T06:43:03.234726Z",
     "shell.execute_reply.started": "2022-02-23T06:42:57.835125Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # 3 = INFO, WARNING, and ERROR messages are not printed\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* c0: safe driving\n",
    "* c1: texting - right\n",
    "* c2: talking on the phone - right\n",
    "* c3: texting - left\n",
    "* c4: talking on the phone - left\n",
    "* c5: operating the radio\n",
    "* c6: drinking\n",
    "* c7: reaching behind\n",
    "* c8: hair and makeup\n",
    "* c9: talking to passenger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T06:43:03.237183Z",
     "iopub.status.busy": "2022-02-23T06:43:03.236965Z",
     "iopub.status.idle": "2022-02-23T06:43:03.242080Z",
     "shell.execute_reply": "2022-02-23T06:43:03.241427Z",
     "shell.execute_reply.started": "2022-02-23T06:43:03.237151Z"
    }
   },
   "outputs": [],
   "source": [
    "activity = {'c0': 'Safe driving', \n",
    "                'c1': 'Texting - right', \n",
    "                'c2': 'Talking on the phone - right', \n",
    "                'c3': 'Texting - left', \n",
    "                'c4': 'Talking on the phone - left', \n",
    "                'c5': 'Operating the radio', \n",
    "                'c6': 'Drinking', \n",
    "                'c7': 'Reaching behind', \n",
    "                'c8': 'Hair and makeup', \n",
    "                'c9': 'Talking to passenger'\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st image of all different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T06:43:03.243794Z",
     "iopub.status.busy": "2022-02-23T06:43:03.243349Z",
     "iopub.status.idle": "2022-02-23T06:43:07.495877Z",
     "shell.execute_reply": "2022-02-23T06:43:07.495133Z",
     "shell.execute_reply.started": "2022-02-23T06:43:03.243761Z"
    }
   },
   "outputs": [],
   "source": [
    "# listdir(path) is used to get the list of all files and directories in path\n",
    "# enumerate(iterator) will give the list of tuple containing counter(starting from 0 by default), value\n",
    "import matplotlib.image as mpimg\n",
    "plt.figure(figsize = (12, 20))\n",
    "image_count = 1\n",
    "BASE_URL = '../input/state-farm-distracted-driver-detection/imgs/train/'\n",
    "for directory in os.listdir(BASE_URL):\n",
    "    if directory[0] != '.':\n",
    "        for i, file in enumerate(os.listdir(BASE_URL + directory)):\n",
    "            if i == 1:\n",
    "                break\n",
    "                # after 0 loop stop. so only 1st will be printed from every folder\n",
    "            else:\n",
    "                fig = plt.subplot(5, 2, image_count)\n",
    "                image_count += 1\n",
    "                image = mpimg.imread(BASE_URL + directory + '/' + file)\n",
    "                plt.imshow(image)\n",
    "                plt.title(activity[directory])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Dimensions of all Images in different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T06:43:07.497988Z",
     "iopub.status.busy": "2022-02-23T06:43:07.497769Z",
     "iopub.status.idle": "2022-02-23T06:43:07.575593Z",
     "shell.execute_reply": "2022-02-23T06:43:07.574936Z",
     "shell.execute_reply.started": "2022-02-23T06:43:07.497959Z"
    }
   },
   "outputs": [],
   "source": [
    "#Checking Dimension of Images:\n",
    "BASE_URL = '../input/state-farm-distracted-driver-detection/imgs/train/'\n",
    "print(\"Dimension of Images :-\")\n",
    "for directory in os.listdir(BASE_URL):\n",
    "    if directory[0] != '.':\n",
    "        for i, file in enumerate(os.listdir(BASE_URL + directory)):\n",
    "            if i == 1:\n",
    "                break\n",
    "                # after 0 loop stop. so only 1st will be printed from every folder\n",
    "            else:\n",
    "                image = mpimg.imread(BASE_URL + directory + '/' + file)\n",
    "                print(directory, \" : \", image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T06:43:07.577920Z",
     "iopub.status.busy": "2022-02-23T06:43:07.577458Z",
     "iopub.status.idle": "2022-02-23T06:43:09.901099Z",
     "shell.execute_reply": "2022-02-23T06:43:09.900417Z",
     "shell.execute_reply.started": "2022-02-23T06:43:07.577881Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating Model\n",
    "# 3 Convolution Layer, 3 Dense Layer and 1 flatten layer is used. adam optimizer and categorical_crossentropy as loss function\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, Activation, MaxPooling2D, Dropout, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 128, kernel_size = (3, 3), activation = 'relu', input_shape = (240, 240, 3), data_format = 'channels_last', padding = \"same\"))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu', padding = \"same\"))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation = 'relu', padding = \"same\"))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 1024, activation = 'relu'))\n",
    "model.add(Dense(units = 256, activation = 'relu'))\n",
    "model.add(Dense(units = 10, activation = 'sigmoid'))\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T06:43:09.902725Z",
     "iopub.status.busy": "2022-02-23T06:43:09.902450Z",
     "iopub.status.idle": "2022-02-23T06:43:29.165898Z",
     "shell.execute_reply": "2022-02-23T06:43:29.165030Z",
     "shell.execute_reply.started": "2022-02-23T06:43:09.902678Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1.0/255, \n",
    "                                   shear_range = 0.2, \n",
    "                                   zoom_range = 0.2, \n",
    "                                   horizontal_flip = True, \n",
    "                                   validation_split = 0.2)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('../input/state-farm-distracted-driver-detection/imgs/train/', \n",
    "                                                 target_size = (240, 240), \n",
    "                                                 batch_size = 32,\n",
    "                                                 subset = 'training')\n",
    "\n",
    "validation_set = train_datagen.flow_from_directory('../input/state-farm-distracted-driver-detection/imgs/train/', \n",
    "                                                   target_size = (240, 240), \n",
    "                                                   batch_size = 32,\n",
    "                                                   subset = 'validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and Checking Accuracy of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T06:43:29.167961Z",
     "iopub.status.busy": "2022-02-23T06:43:29.167448Z",
     "iopub.status.idle": "2022-02-23T07:42:25.384904Z",
     "shell.execute_reply": "2022-02-23T07:42:25.384253Z",
     "shell.execute_reply.started": "2022-02-23T06:43:29.167923Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fit_generator(training_set,\n",
    "                         steps_per_epoch = 17943/32,\n",
    "                         epochs = 10,\n",
    "                         validation_data = validation_set,\n",
    "                         validation_steps = 4481/32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model is working with 98% accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
